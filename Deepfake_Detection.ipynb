{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ResNet-50"
      ],
      "metadata": {
        "id": "WO_PdDBLZzcq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBkhsdssYJ41"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_resnet_model():\n",
        "\n",
        "    # Load the pre-trained ResNet50 model without the top layer\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    # Freeze the weights of the pre-trained layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    # Add the final classification layer with sigmoid activation for binary classification\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Z8ShrArxYXgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the ResNet-based model\n",
        "resnet_model = create_resnet_model()\n",
        "\n",
        "# Compile the model using RMSprop optimizer, binary crossentropy loss, and accuracy metric\n",
        "resnet_model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "cILTyM-JYfFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a checkpoint callback\n",
        "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "# Train the model for 10 epochs with a batch size of 32 and a validation split of 0.1\n",
        "resnet_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, callbacks=[checkpoint])\n"
      ],
      "metadata": {
        "id": "lR8REAhgYrl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "resnet_model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "ldYemQlfYs_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model from the checkpoint\n",
        "resnet_model.load_weights(\"best_model.h5\")\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_resnet = resnet_model.predict(X_test)\n",
        "\n",
        "# Convert the predictions to binary labels (0 or 1) using a threshold of 0.5\n",
        "y_pred_resnet = (y_pred_resnet > 0.5).astype(int)\n"
      ],
      "metadata": {
        "id": "E_CDP-C0YueQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred_resnet))"
      ],
      "metadata": {
        "id": "RVGp0ItfYv6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN (adam optimizer):"
      ],
      "metadata": {
        "id": "7QH8WgSSY9o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "nXFIlJYFY-ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_dir = \"/kaggle/input/celeb-real\"\n",
        "fake_dir = \"/kaggle/input/celeb-synthesis\"\n"
      ],
      "metadata": {
        "id": "VT_TUdJgZZVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames(video_dir, image_dir):\n",
        "    if not os.path.exists(image_dir):\n",
        "        os.makedirs(image_dir)\n",
        "    for video in os.listdir(video_dir):\n",
        "        cap = cv2.VideoCapture(os.path.join(video_dir, video))\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        frame_index = np.random.randint(0, frame_count)\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)\n",
        "        success, frame = cap.read()\n",
        "        if success:\n",
        "            frame = cv2.resize(frame, (224, 224))\n",
        "            video_name = os.path.splitext(video)[0]\n",
        "            image_name = video_name + \"_\" + str(frame_index) + \".jpg\"\n",
        "            cv2.imwrite(os.path.join(image_dir, image_name), frame)\n",
        "        cap.release()\n"
      ],
      "metadata": {
        "id": "JGra3ZpPZazb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extract_frames(real_dir, \"/kaggle/working/real_images\")\n",
        "extract_frames(fake_dir, \"/kaggle/working/fake_images\")\n"
      ],
      "metadata": {
        "id": "5Gyg9q_OZcgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(image_dirs, labels):\n",
        "    images = []\n",
        "    image_labels = []\n",
        "    for image_dir, label in zip(image_dirs, labels):\n",
        "        for image in os.listdir(image_dir):\n",
        "            img = cv2.imread(os.path.join(image_dir, image))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = img / 255.0\n",
        "            images.append(img)\n",
        "            image_labels.append(label)\n",
        "    images = np.array(images)\n",
        "    image_labels = np.array(image_labels)\n",
        "    return images, image_labels\n"
      ],
      "metadata": {
        "id": "GwpraXb-ZeIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_data([\"/kaggle/working/real_images\", \"/kaggle/working/fake_images\"], [0, 1])\n"
      ],
      "metadata": {
        "id": "Vbs8k2qMZfxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "s26c2mUOZhSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "_YkUooD6Zijb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "p6IQkN_FZj_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\"best_model.h5\", save_best_only=True, monitor=\"val_loss\", mode=\"min\")\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, callbacks=[checkpoint])\n"
      ],
      "metadata": {
        "id": "2Ge9BTYRZlXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "XEVfut84Zmy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"best_model.h5\")\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n"
      ],
      "metadata": {
        "id": "s9yOp89wZoKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "1n7ANapPZpnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XceptionNet"
      ],
      "metadata": {
        "id": "SINLHlLNZ1xD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "FrJfKkIYaBcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data transformations for training and validation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((299, 299)), # Resize for Xception input size\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((299, 299)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load custom dataset\n",
        "train_data = datasets.ImageFolder('path_to_training_data', transform=train_transforms)\n",
        "val_data = datasets.ImageFolder('path_to_validation_data', transform=val_transforms)\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=32)\n"
      ],
      "metadata": {
        "id": "8OVBTf4vaqHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained Xception model\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'xception', pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2) # Assuming 2 classes: Real and Fake\n",
        "\n",
        "# Freeze initial layers and only train the last few layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.fc.parameters():\n",
        "    param.requires_grad = True\n"
      ],
      "metadata": {
        "id": "zPoobi6DaroY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer with weight decay\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "weight_decay = 1e-4\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001, weight_decay=weight_decay)\n",
        "\n",
        "# Define learning rate scheduler\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n"
      ],
      "metadata": {
        "id": "JB8j_QYsatcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "pvDUHT1oauu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with learning rate scheduling\n",
        "num_epochs = 10\n",
        "best_accuracy = 0.0\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "    # Update learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_accuracy = correct_predictions / total_predictions\n",
        "    if epoch_accuracy > best_accuracy:\n",
        "        best_accuracy = epoch_accuracy\n",
        "        torch.save(model.state_dict(), \"best_xception_model.pth\") # Save the best model\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_data)}, Accuracy: {epoch_accuracy}\")\n",
        "print(f\"Best Validation Accuracy: {best_accuracy}\")\n"
      ],
      "metadata": {
        "id": "MoJRNRQfawAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "model_name = 'Wvolf/ViT_Deepfake_Detection'\n",
        "model = ViTForImageClassification.from_pretrained(model_name)\n",
        "\n",
        "# Define transformations to preprocess the uploaded image\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
        "transform = lambda img: feature_extractor(img, return_tensors='pt')\n",
        "\n",
        "# Function to process an image and get the predicted label\n",
        "def get_predicted_label(image_path):\n",
        "    uploaded_image = Image.open(image_path)\n",
        "    processed_image = transform(uploaded_image)['pixel_values']\n",
        "\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        outputs = model(processed_image)\n",
        "        predictions = F.softmax(outputs.logits, dim=1)\n",
        "        predicted_class = torch.argmax(predictions, dim=1).item()\n",
        "\n",
        "    # Decode the predicted class (0 for Real, 1 for Fake)\n",
        "    class_labels = ['Real', 'Fake']\n",
        "    predicted_label = class_labels[predicted_class]\n",
        "    return predicted_label\n"
      ],
      "metadata": {
        "id": "-phvpyANaxZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to the real and fake faces directories\n",
        "real_faces_dir = \"/content/drive/MyDrive/real_faces/real_faces/DeepFake00/DeepFake00\"\n",
        "fake_faces_dir = \"/content/drive/MyDrive/fake_faces/fake_faces/DeepFake02/DeepFake02\"\n",
        "\n",
        "# Get the list of image files in each directory\n",
        "real_images = [os.path.join(real_faces_dir, file) for file in os.listdir(real_faces_dir) if file.endswith('.jpg')]\n",
        "fake_images = [os.path.join(fake_faces_dir, file) for file in os.listdir(fake_faces_dir) if file.endswith('.jpg')]\n",
        "\n",
        "# Calculate accuracy for real faces\n",
        "total_real_images = len(real_images)\n",
        "if total_real_images > 0:\n",
        "    correct_predictions_real = 0\n",
        "\n",
        "    for image_path in real_images:\n",
        "        predicted_label = get_predicted_label(image_path)\n",
        "\n",
        "        if predicted_label == 'Real':\n",
        "            correct_predictions_real += 1\n",
        "\n",
        "    accuracy_real = correct_predictions_real / total_real_images\n",
        "else:\n",
        "    accuracy_real = 0.0 # Set accuracy to 0 if there are no real images\n",
        "\n",
        "# Calculate accuracy for fake faces\n",
        "total_fake_images = len(fake_images)\n",
        "if total_fake_images > 0:\n",
        "    correct_predictions_fake = 0\n",
        "\n",
        "    for image_path in fake_images:\n",
        "        predicted_label = get_predicted_label(image_path)\n",
        "\n",
        "        if predicted_label == 'Fake':\n",
        "            correct_predictions_fake += 1\n",
        "\n",
        "    accuracy_fake = correct_predictions_fake / total_fake_images\n",
        "else:\n",
        "    accuracy_fake = 0.0 # Set accuracy to 0 if there are no fake images\n",
        "\n",
        "# Calculate accuracy for all faces (real and fake)\n",
        "total_images = total_real_images + total_fake_images\n",
        "if total_images > 0:\n",
        "    correct_predictions_all = correct_predictions_real + correct_predictions_fake\n",
        "    accuracy_all = correct_predictions_all / total_images\n",
        "else:\n",
        "    accuracy_all = 0.0 # Set accuracy to 0 if there are no images\n",
        "\n",
        "print(f'Overall Accuracy: {accuracy_all * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "xaM7sRsxazH5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}